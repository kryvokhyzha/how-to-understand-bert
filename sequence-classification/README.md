# Sequence classification ðŸ’¡
There you can find some notebooks with examples of usage BERT for sequence classification.

## Notebooks
+ **bert-fine-tuning-sentence-classification-v1.ipynb** - this tutorial shows how to use BERT with the huggingface PyTorch library to quickly and efficiently fine-tune a model to get near state of the art performance in sentence classification. [Original notebook](https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX). [Video tutorial](https://www.youtube.com/watch?v=x66kkDnbzi4&list=PLam9sigHPGwOBuH4_4fr-XvDbe5uneaf6&index=3).

+ **bert-fine-tuning-sentence-classification-v2.ipynb** - this notebook is the same as the previous one, but some steps were done by hand (without using huggingface features)

+ **sentiment-analysis-with-bert.ipynb** - this tutorial shows how to fine-tune BERT for sentiment analysis.[Original post](https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/).

+ **sentiment-analysis-with-bert-pytorch-lightning.ipynb** - this tutorial shows how to fine-tune DistilBERT for sentiment analysis using pytorch-lightning.

+ **a-visual-notebook-to-using-bert-for-the-first-time.ipynb** - in this notebook, we will use pre-trained deep learning model to solve text sentiment analysis task. First part of this notebook belongs to Jay Alammar and his [great blog post](http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/) (while it has minor changes). His blog is a great way to dive into the DL and NLP concepts.

+ [ru] **russian-tweet-sentiment-analysis-with-bert.ipynb** - a simple notebook with an example of text tokenization by hand

## Additional sources
   + [en] [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)