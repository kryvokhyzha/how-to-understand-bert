# Sequence classification ðŸ’¡
There you can find some notebooks with examples of usage BERT for sequence classification.

## Notebooks
+ **bert-fine-tuning-sentence-classification-v1.ipynb** - this tutorial shows how to use BERT with the huggingface PyTorch library to quickly and efficiently fine-tune a model to get near state of the art performance in sentence classification. [Original notebook](https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX). [Video tutorial](https://www.youtube.com/watch?v=x66kkDnbzi4&list=PLam9sigHPGwOBuH4_4fr-XvDbe5uneaf6&index=3).

+ **bert-fine-tuning-sentence-classification-v2.ipynb** - this notebook is the same as the previous one, but some steps were done by hand (without using huggingface features)

+ **sentiment-analysis-with-bert.ipynb** - this tutorial shows how to fine-tune BERT for sentiment analysis.[Original post](https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/).

+ **sentiment-analysis-with-bert-pytorch-lightning.ipynb** - this tutorial shows how to fine-tune DistilBERT for sentiment analysis using pytorch-lightning.

+ **** - this tutorial shows how to use fine-tune BERT for _document classification_ task using the [Wikipedia Personal Attacks dataset](https://github.com/ewulczyn/wiki-detox/blob/master/src/figshare/Wikipedia%20Talk%20Data%20-%20Getting%20Started.ipynb) as an example. [Original notebook](https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP)

## Additional sources
   + [en] [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)